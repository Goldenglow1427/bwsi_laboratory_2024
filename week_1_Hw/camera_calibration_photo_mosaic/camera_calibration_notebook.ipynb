{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a jupyter notebook created for camera calibration practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Define parameters, setup settings, and read the images.\n",
    "\n",
    "Reference:\n",
    "\n",
    "- [OpenCV on Camera Calibration](https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define checkerboard_dims as (9, 6) \n",
    "checkboard_dims = (9, 6)\n",
    "\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Create objp as a zero array of shape (number of corners, 3), float32\n",
    "# Set the first two columns of objp to the coordinate grid of corners\n",
    "objp = np.zeros((7*6, 3), dtype=np.float32) # Refer to OpenCV on Camera Calibration.\n",
    "objp[:, :2] = np.mgrid[0:7, 0:6].T.reshape(-1, 2)\n",
    "\n",
    "# Initialize objpoints as an empty list\n",
    "objpoints: list = []\n",
    "# Initialize imgpoints as an empty list\n",
    "imgpoints: list = []\n",
    "\n",
    "# Load all checkerboard images using glob ('path/to/images/*.jpg')\n",
    "images = glob.glob(\"calibration photos/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if the previous code segment is working.\n",
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Find the locations of corners in the image, and store them in `imgpoints` and `objpoints`.\n",
    "\n",
    "Reference:\n",
    "\n",
    "- [OpenCV on Camera Calibration](https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 0\n",
      "Done Processing image 0\n",
      "Processing image 1\n",
      "Done Processing image 1\n",
      "Processing image 2\n",
      "Done Processing image 2\n",
      "Processing image 3\n",
      "Done Processing image 3\n",
      "Processing image 4\n",
      "Done Processing image 4\n",
      "Processing image 5\n",
      "Done Processing image 5\n",
      "Processing image 6\n",
      "Done Processing image 6\n",
      "Processing image 7\n",
      "Done Processing image 7\n",
      "Processing image 8\n",
      "Done Processing image 8\n",
      "Processing image 9\n",
      "Done Processing image 9\n",
      "Processing image 10\n",
      "Done Processing image 10\n",
      "Processing image 11\n",
      "Done Processing image 11\n",
      "Processing image 12\n",
      "Done Processing image 12\n",
      "Processing image 13\n",
      "Done Processing image 13\n",
      "Processing image 14\n",
      "Done Processing image 14\n",
      "Processing image 15\n",
      "Done Processing image 15\n",
      "Processing image 16\n",
      "Done Processing image 16\n",
      "Processing image 17\n",
      "Done Processing image 17\n",
      "Processing image 18\n",
      "Done Processing image 18\n",
      "Processing image 19\n",
      "Done Processing image 19\n"
     ]
    }
   ],
   "source": [
    "# Initialize objpoints as an empty list\n",
    "objpoints: list = []\n",
    "# Initialize imgpoints as an empty list\n",
    "imgpoints: list = []\n",
    "\n",
    "# For each image in images:\n",
    "for (image, i) in zip(images, range(len(images))):\n",
    "    print(f\"Processing image {i}\")\n",
    "\n",
    "    # Read the image\n",
    "    img = cv.imread(images[i])\n",
    "    # Convert the image to grayscale\n",
    "    gray_img = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Find the chessboard corners in the grayscale image\n",
    "    ret, corners = cv.findChessboardCorners(gray_img, (7, 6), None)\n",
    "    # If corners are found:\n",
    "    if ret == True:\n",
    "        # Append objp to objpoints\n",
    "        objpoints.append(objp)\n",
    "        # Refine corner positions using cornerSubPix\n",
    "        criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "        corners2 = cv.cornerSubPix(gray_img, corners, (11, 11), (-1, -1), criteria)\n",
    "        # Append refined corners to imgpoints\n",
    "        imgpoints.append(corners2)\n",
    "\n",
    "        # Optionally, draw chessboard corners on the image\n",
    "        # cv.drawChessboardCorners(img, (7, 6), corners2, ret)\n",
    "        # Optionally, display the image with drawn corners\n",
    "        # cv.imshow(\"Edited Image\", img)\n",
    "        # Wait for a short period\n",
    "        # cv.waitKey(2000)\n",
    "\n",
    "    print(f\"Done Processing image {i}\")\n",
    "    \n",
    "# Destroy all OpenCV windows\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plt.imshow(cv.imread(images[10]))\n",
    "len(imgpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Calibrate the camera based on the obtained outcome, and verify the calibration.\n",
    "\n",
    "Reference:\n",
    "\n",
    "- [OpenCV on Camera Calibration](https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 76,  75,  74, ..., 103, 101,  95],\n",
       "       [ 70,  69,  68, ..., 109, 107, 101],\n",
       "       [ 74,  73,  72, ..., 109, 107, 103],\n",
       "       ...,\n",
       "       [153, 148, 146, ..., 131, 134, 136],\n",
       "       [156, 153, 150, ..., 140, 143, 144],\n",
       "       [153, 153, 152, ..., 143, 146, 146]], dtype=uint8)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_img[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate the camera using calibrateCamera with objpoints, imgpoints, and image size\n",
    "# Get the camera matrix, distortion coefficients, rotation vectors, and translation vectors\n",
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray_img.shape[::-1], None, None)\n",
    "\n",
    "# Save the calibration results (camera matrix, distortion coefficients) to a file.\n",
    "np.savez_compressed(\"/home/nahida/Documents/GitHub/bwsi_laboratory_2024/week_1_Hw/camera_calibration_photo_mosaic/camera.npz\",\n",
    "        cam_mat = mtx, dist_coef = dist, rot_vec = rvecs, tra_vec = tvecs) \n",
    "# A common and convenient format for storing camera calibration data is the NumPy .npz file format,\n",
    "    # which allows you to store multiple NumPy arrays in a single compressed file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the calibration:\n",
    "def verify_calibration(obj_points, img_points, r_vecs, t_vecs, matrix, distortion):\n",
    "    # Initialize mean_error to 0\n",
    "    mean_error = 0\n",
    "    # For each pair of object points and image points:\n",
    "    for objpoint, imgpoint, rvec, tvec in zip(obj_points, img_points, r_vecs, t_vecs):\n",
    "        # Project the object points to image points using projectPoints\n",
    "        imgpoints2, _ = cv.projectPoints(objpoint, rvec, tvec, matrix, distortion)\n",
    "        # Compute the error between the projected and actual image points\n",
    "        error = cv.norm(imgpoint, imgpoints2, cv.NORM_L2) / len(imgpoints2)\n",
    "        # Accumulate the error\n",
    "        mean_error += error\n",
    "\n",
    "    # Compute the average error\n",
    "    mean_error /= len(obj_points)\n",
    "    # Print the total average error\n",
    "    # print(mean_error)\n",
    "    return mean_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07728077072556332"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify_calibration(objpoints, imgpoints, rvecs, tvecs, mtx, dist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
